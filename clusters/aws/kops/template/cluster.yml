  {{- $awsRegion := .awsRegion }}
  {{- $networkPortion := .networkPortion }}
  {{- $kopsName := .kopsName }}
  {{- $dnsZone := .dnsZone }}
  {{- $instanceGroups := .instanceGroups }}
  {{- $availabilityZonesAll := .availabilityZonesAll }}
  {{- $env := .env }}
  {{- $registryMirrors := .docker.registryMirrors }}
  {{- $registryProxy := .docker.registryProxy }}
  {{- $cloudLabels := .cloudLabels }}
  {{- $availabilityZonesPrivate := .availabilityZonesPrivate }}

apiVersion: kops/v1alpha2
kind: Cluster
metadata:
  name: {{ .kopsName }}.{{ .dnsZone }}
spec:
  hooks:
  ### https://github.com/kubernetes/kops/pull/6646
  ### https://github.com/kubernetes/kops/pull/8903
{{- if .cloudLabels }}
  cloudLabels:
    {{- range $key, $value := $cloudLabels }}
    {{ $key }}: "{{ $value }}"
    {{- end }}
{{- end }}
  fileAssets:
    - name: apparmor-namespace
      roles: [nodes]
      content: |
        apiVersion: v1
        kind: Namespace
        metadata:
          name: apparmor
          labels:
            name: apparmor
            ## https://github.com/Shopify/kubeaudit/blob/master/docs/auditors/netpols.md
            audit.kubernetes.io/namespace.allow-non-default-deny-ingress-network-policy: ""
            audit.kubernetes.io/namespace.allow-non-default-deny-egress-network-policy: ""
    - name: PodSecurityPolicy
      roles: [nodes]
      content: |
        apiVersion: policy/v1beta1
        kind: PodSecurityPolicy
        metadata:
          annotations:
            apparmor.security.beta.kubernetes.io/allowedProfileNames: localhost/default
            apparmor.security.beta.kubernetes.io/defaultProfileName: localhost/default
            k8s-addon: podsecuritypolicy.addons.k8s.io
          name: kube-system
        spec:
          allowPrivilegeEscalation: true
          allowedCapabilities:
            - '*'
          fsGroup:
            rule: RunAsAny
          hostIPC: true
          hostNetwork: true
          hostPID: true
          hostPorts:
            - max: 65536
              min: 1
          privileged: true
          runAsUser:
            rule: RunAsAny
          seLinux:
            rule: RunAsAny
          supplementalGroups:
            rule: RunAsAny
          volumes:
            - '*'
    - name: apparmor-profiles
      roles: [nodes]
      content: |
        apiVersion: v1
        data:
          default: |-
            #include <tunables/global>

            # From https://github.com/jfrazelle/bane/blob/master/docker-nginx-sample
            profile default flags=(attach_disconnected,mediate_deleted) {
              #include <abstractions/base>

              network inet tcp,
              network inet udp,
              network inet icmp,

              deny network raw,

              deny network packet,

              file,
              umount,

              deny /bin/** wl,
              deny /boot/** wl,
              deny /dev/** wl,
              deny /etc/** wl,
              deny /home/** wl,
              deny /lib/** wl,
              deny /lib64/** wl,
              deny /media/** wl,
              deny /mnt/** wl,
              deny /opt/** wl,
              deny /proc/** wl,
              deny /root/** wl,
              deny /sbin/** wl,
              deny /srv/** wl,
              deny /tmp/** wl,
              deny /sys/** wl,
              deny /usr/** wl,

              audit /** w,

              /var/run/nginx.pid w,

              /usr/sbin/nginx ix,

              deny /bin/dash mrwklx,
              deny /bin/sh mrwklx,
              deny /usr/bin/top mrwklx,

              capability chown,
              capability dac_override,
              capability setuid,
              capability setgid,
              capability net_bind_service,

              deny @{PROC}/{*,**^[0-9*],sys/kernel/shm*} wkx,
              deny @{PROC}/sysrq-trigger rwklx,
              deny @{PROC}/mem rwklx,
              deny @{PROC}/kmem rwklx,
              deny @{PROC}/kcore rwklx,
              deny mount,
              deny /sys/[^f]*/** wklx,
              deny /sys/f[^s]*/** wklx,
              deny /sys/fs/[^c]*/** wklx,
              deny /sys/fs/c[^g]*/** wklx,
              deny /sys/fs/cg[^r]*/** wklx,
              deny /sys/firmware/efi/efivars/** rwklx,
              deny /sys/kernel/security/** rwklx,
            }
        kind: ConfigMap
        metadata:
          name: apparmor-profiles
          namespace: apparmor
    - name: apparmor-daemonset
      roles: [nodes]
      content: |
        apiVersion: apps/v1
        kind: DaemonSet
        metadata:
          labels:
            daemon: apparmor-loader
          name: apparmor-loader
          namespace: apparmor
        spec:
          selector:
            matchLabels:
              daemon: apparmor-loader
          template:
            metadata:
              labels:
                daemon: apparmor-loader
              name: apparmor-loader
              annotations:
                container.apparmor.security.beta.kubernetes.io/apparmor-loader: runtime/default
            spec:
              containers:
                - args:
                    - -poll
                    - 30s
                    - /profiles
                  image: google/apparmor-loader:latest
                  name: apparmor-loader
                  securityContext:
                    privileged: false
                    allowPrivilegeEscalation: false
                    capabilities:
                      drop:
                        - AUDIT_WRITE
                        - CHOWN
                        - DAC_OVERRIDE
                        - FOWNER
                        - FSETID
                        - KILL
                        - MKNOD
                        - NET_BIND_SERVICE
                        - NET_RAW
                        - SETFCAP
                        - SETGID
                        - SETPCAP
                        - SETUID
                        - SYS_CHROOT
                    readOnlyRootFilesystem: true
                    runAsNonRoot: true
                  volumeMounts:
                    - mountPath: /sys
                      name: sys
                      readOnly: true
                    - mountPath: /etc/apparmor.d
                      name: apparmor-includes
                      readOnly: true
                    - mountPath: /profiles
                      name: profiles
                      readOnly: true
                  resources: {}
              volumes:
                - hostPath:
                    path: /sys
                  name: sys
                - hostPath:
                    path: /etc/apparmor.d
                  name: apparmor-includes
                - configMap:
                    name: apparmor-profiles
                  name: profiles
              automountServiceAccountToken: false
          updateStrategy: {}
        status:
          currentNumberScheduled: 0
          desiredNumberScheduled: 0
          numberMisscheduled: 0
          numberReady: 0

    # https://github.com/kubernetes/kops/blob/master/docs/cluster_spec.md#audit-logging
    - name: apiserver-audit-policy
      path: /srv/kubernetes/audit.yaml
      roles: [Master]
      content: |
        # apiVersion: audit.k8s.io/v1 # This is /v1 resource is not valid yet.
        apiVersion: audit.k8s.io/v1beta1
        kind: Policy
        # Don't generate audit events for all requests in RequestReceived stage.
        omitStages:
          - "RequestReceived"
        rules:
          # Log pod changes at RequestResponse level
          - level: RequestResponse
            resources:
            - group: ""
              # Resource "pods" doesn't match requests to any subresource of pods,
              # which is consistent with the RBAC policy.
              resources: ["pods"]
          # Log "pods/log", "pods/status" at Metadata level
          - level: Metadata
            resources:
            - group: ""
              resources: ["pods/log", "pods/status"]
          # Don't log requests to a configmap called "controller-leader"
          - level: None
            resources:
            - group: ""
              resources: ["configmaps"]
              resourceNames: ["controller-leader"]
          # Don't log watch requests by the "system:kube-proxy" on endpoints or services
          - level: None
            users: ["system:kube-proxy"]
            verbs: ["watch"]
            resources:
            - group: "" # core API group
              resources: ["endpoints", "services"]
          # Don't log authenticated requests to certain non-resource URL paths.
          - level: None
            userGroups: ["system:authenticated"]
            nonResourceURLs:
            - "/api*" # Wildcard matching.
            - "/version"
          # Log the request body of configmap changes in kube-system.
          - level: Request
            resources:
            - group: "" # core API group
              resources: ["configmaps"]
            # This rule only applies to resources in the "kube-system" namespace.
            # The empty string "" can be used to select non-namespaced resources.
            namespaces: ["kube-system"]
          # Log configmap and secret changes in all other namespaces at the Metadata level.
          - level: Metadata
            resources:
            - group: "" # core API group
              resources: ["secrets", "configmaps"]
          # Log all other resources in core and extensions at the Request level.
          - level: Request
            resources:
            - group: "" # core API group
            - group: "extensions" # Version of group should NOT be included.
          # A catch-all rule to log all other requests at the Metadata level.
          - level: Metadata
            # Long-running requests like watches that fall under this rule will not
            # generate an audit event in RequestReceived.
            omitStages:
              - "RequestReceived"

  additionalPolicies:
    node: |
      [
        {"Effect":"Allow","Action":["autoscaling:DescribeAutoScalingGroups","autoscaling:DescribeAutoScalingInstances","autoscaling:DescribeLaunchConfigurations","autoscaling:DescribeTags","autoscaling:SetDesiredCapacity","autoscaling:TerminateInstanceInAutoScalingGroup"],"Resource":"*"}
      ]
  sshKeyName: {{ .sshKeyName }}
  networkID: {{ .vpc }}
  kubernetesApiAccess:
  {{- range $key, $value := .kubernetesApiAccess }}
  - "{{ $value }}"
  {{- end }}
  api:
    dns: {}
    loadBalancer:
      type: {{ .api.loadBalancer.type }}
      idleTimeoutSeconds: 1800
  authorization:
    rbac: {}
  docker:
    registryMirrors: {{ .docker.registryMirrors }}
{{- if .docker.overrides }}
    bridgeIP: {{ .docker.bridgeIP }}
{{- end }}
    logDriver: json-file
    logOpt:
    - max-size=10m
    - max-file=5
  channel: stable
  cloudProvider: aws
  configBase: s3://{{ .s3BucketName }}/{{ .kopsName }}.{{ .dnsZone }}
  etcdClusters:
    # https://github.com/kubernetes/kops/blob/master/docs/cluster_spec.md#etcdclusters-v3--tls
    - backups:
        backupStore: s3://{{ .s3BucketName }}/{{ .kopsName }}.{{ .dnsZone }}/backups/etcd/main
      enableEtcdTLS: true
      # https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md#example-hardware-configurations
      cpuRequest: 200m
      memoryRequest: 128Mi
      etcdMembers:
      {{- range $key, $value := .availabilityZonesEtcd }}
      - instanceGroup: master-{{ $awsRegion }}{{ $value.masterZoneName }}
        name: {{ $value.etcdName }}
        encryptedVolume: true
      {{- end }}
      name: main
      version: {{ .etcd.version }}
    - backups:
        backupStore: s3://{{ .s3BucketName }}/{{ .kopsName }}.{{ .dnsZone }}/backups/etcd/events
      enableEtcdTLS: true
      # https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md#example-hardware-configurations
      cpuRequest: 200m
      memoryRequest: 128Mi
      etcdMembers:
      {{- range $key, $value := .availabilityZonesEtcd }}
      - instanceGroup: master-{{ $awsRegion }}{{ $value.masterZoneName }}
        name: {{ $value.etcdName }}
        encryptedVolume: true
      {{- end }}
      name: events
      version: {{ .etcd.version }}
  iam:
    # https://github.com/kubernetes/kops/blob/master/docs/iam_roles.md#iam-roles
    allowContainerRegistry: {{ .iam.allowContainerRegistry }}
    legacy: false
  kubeAPIServer:
{{- if .oidc.enabled }}
    oidcIssuerURL: {{ .oidc.oidcIssuerURL }}
    oidcClientID: {{ .oidc.oidcClientID }}
    oidcGroupsClaim: groups
{{- end }}
    # configs: https://github.com/kubernetes/kops/blob/master/pkg/apis/kops/componentconfig.go
    auditLogPath: /var/log/kube-apiserver-audit.log
    auditLogMaxAge: 30
    auditLogMaxBackups: 10
    auditLogMaxSize: 100
    auditPolicyFile: /srv/kubernetes/audit.yaml
    ## https://github.com/kubernetes/kops/blob/master/docs/cluster_spec.md#disable-basic-auth
    ## Support for basic authentication was deprecated in Kubernetes 1.16 and removed in Kubernetes 1.19.
    disableBasicAuth: {{ .kubeAPIServer.disableBasicAuth }}
    anonymousAuth: false
    tlsMinVersion: VersionTLS12
    ## https://github.com/traefik/traefik/issues/2466#issuecomment-347022645
    tlsCipherSuites: [ "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305", "TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA", "TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA", "TLS_RSA_WITH_AES_128_GCM_SHA256", "TLS_RSA_WITH_AES_256_GCM_SHA384", "TLS_RSA_WITH_AES_128_CBC_SHA", "TLS_RSA_WITH_AES_256_CBC_SHA" ]
    ## https://github.com/kubernetes/kubernetes/blob/master/pkg/kubeapiserver/options/plugins.go#L64-L106
    admissionControl:
      - AlwaysPullImages
      - NamespaceLifecycle
      - LimitRanger
      - ServiceAccount
      - PersistentVolumeLabel
      - DefaultStorageClass
      - DefaultTolerationSeconds
      - MutatingAdmissionWebhook
      - ValidatingAdmissionWebhook
      - ResourceQuota
      - NodeRestriction
      - Priority
{{ if .PodSecurityPolicy.enabled }}
      - PodSecurityPolicy
{{- end }}
  kubeControllerManager:
    terminatedPodGCThreshold: 10
    tlsMinVersion: VersionTLS12
    ## https://github.com/traefik/traefik/issues/2466#issuecomment-347022645
    tlsCipherSuites: [ "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305", "TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA", "TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA", "TLS_RSA_WITH_AES_128_GCM_SHA256", "TLS_RSA_WITH_AES_256_GCM_SHA384", "TLS_RSA_WITH_AES_128_CBC_SHA", "TLS_RSA_WITH_AES_256_CBC_SHA" ]
  kubelet:
    protectKernelDefaults: true
    ## https://github.com/kubernetes/kops/blob/master/docs/security.md#kubelet-api
    anonymousAuth: false
    ## https://github.com/kubernetes/kops/blob/master/docs/releases/1.16-NOTES.md#required-actions
    featureGates:
      PodPriority: "true"
    tlsMinVersion: VersionTLS12
    ## https://github.com/traefik/traefik/issues/2466#issuecomment-347022645
    tlsCipherSuites: [ "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256", "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305", "TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA", "TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA", "TLS_RSA_WITH_AES_128_GCM_SHA256", "TLS_RSA_WITH_AES_256_GCM_SHA384", "TLS_RSA_WITH_AES_128_CBC_SHA", "TLS_RSA_WITH_AES_256_CBC_SHA" ]
    # https://github.com/kubernetes-sigs/metrics-server/issues/212
    authenticationTokenWebhook: true
    authorizationMode: Webhook
  kubeDNS:
    provider: CoreDNS
    ## https://github.com/kubernetes/kops/blob/master/docs/cluster_spec.md#node-local-dns-cache
    nodeLocalDNS:
      enabled: true
      memoryRequest: 5Mi
      cpuRequest: 25m
  kubernetesVersion: {{ .kubernetesVersion }}
  masterPublicName: api.{{ .kopsName }}.{{ .dnsZone }}
  networkCIDR: {{ .networkCIDR }}
  networking:
    canal:
      mtu: 8912
  nonMasqueradeCIDR: 100.64.0.0/10
  sshAccess:
  {{- range $key, $value := .sshAccess }}
  - "{{ $value }}"
  {{- end }}
  subnets:
  {{- range $subnet := .subnets }}
    {{- range $key, $value := $subnet.blocks }}
  - cidr: {{ $value.cidr }}
    type: {{ $subnet.type }}
      {{- if eq $subnet.type "Private" }}
    name: {{ $subnet.name }}-{{ with (index $availabilityZonesPrivate $key) }}{{ .zone }}{{ end }}
    zone: {{ $awsRegion }}{{ with (index $availabilityZonesPrivate $key) }}{{ .zone }}{{ end }}
        {{- with (index $availabilityZonesPrivate $key) }}
          {{- if (index . "egress")  }}
    egress: {{ .egress }}
          {{- end }}
          {{- end }}
      {{- else }}
    name: {{ $subnet.name }}-{{ with (index $availabilityZonesAll $key) }}{{ .zone }}{{ end }}
    zone: {{ $awsRegion }}{{ with (index $availabilityZonesAll $key) }}{{ .zone }}{{ end }}
      {{- end }}
    {{- end }}
  {{- end }}

  topology:
    dns:
      type: {{ .topology.dns.type }}
    masters: {{ .topology.masters }}
    nodes: {{ .topology.nodes }}

{{- range $key, $value := .availabilityZonesKubeMaster }}
---
apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
  labels:
    kops.k8s.io/cluster: {{ $kopsName }}.{{ $dnsZone }}
  name: master-{{ $awsRegion }}{{ $value.name }}
spec:
  additionalUserData:
    - name: protect-kernel-defaults.sh
      type: text/x-shellscript
      content: |
        #!/bin/sh
        cat <<EOF > /etc/sysctl.d/90-kubelet.conf
        vm.overcommit_memory=1
        kernel.panic=10
        kernel.panic_on_oops=1
        EOF
        sysctl -p /etc/sysctl.d/90-kubelet.conf
{{- if $registryProxy }}
    - name: docker-registry-proxy.sh
      type: text/x-shellscript
      content: |
        #!/bin/sh

        # Add environment vars pointing Docker to use the proxy
        # https://docs.docker.com/config/daemon/systemd/#httphttps-proxy

        mkdir -p /etc/systemd/system/docker.service.d
        cat << EOD > /etc/systemd/system/docker.service.d/http-proxy.conf
        [Service]
        Environment="HTTP_PROXY={{ $registryProxy }}"
        Environment="HTTPS_PROXY={{ $registryProxy }}"
        EOD

        # Get the CA certificate from the proxy and make it a trusted root.
        curl {{ $registryProxy }}ca.crt > /usr/share/ca-certificates/docker_registry_proxy.crt
        echo "docker_registry_proxy.crt" >> /etc/ca-certificates.conf
        update-ca-certificates --fresh

        # Reload systemd
        systemctl daemon-reload

        # Restart dockerd
        systemctl restart docker.service
{{- end }}
  cloudLabels:
    {{- range $key, $value := $instanceGroups.kubeMaster.cloudLabels }}
      {{ $key }}: "{{ $value }}"
      {{- end }}
  image: {{ $instanceGroups.kubeMaster.image }}
  machineType: {{ $instanceGroups.kubeMaster.machineType }}
  maxSize: {{ $instanceGroups.kubeMaster.maxSize }}
  minSize: {{ $instanceGroups.kubeMaster.minSize }}
  nodeLabels:
    {{- if $instanceGroups.kubeMaster.nodeLabels }}
    {{- range $key, $value := $instanceGroups.kubeMaster.nodeLabels }}
    {{ $key }}: "{{ $value }}"
    {{- end }}
    {{- end }}
    kops.k8s.io/instancegroup: master-{{ $awsRegion }}{{ $value.name }}
    kubernetes-ops/isSpot: "false"
    kubernetes-ops/instanceType: {{ $instanceGroups.kubeMaster.machineType }}
  role: Master
  subnets:
    - kube-master-{{ $value.name }}
{{- end }}

  #
  # Bastion workers group
  # https://github.com/kubernetes/kops/blob/master/docs/bastion.md#configure-the-bastion-instance-group
  #
  {{- if .enableBastionGroup1 -}}
  {{- range $key, $value := .availabilityZonesAll }}
  {{- if eq $value.zone (index $availabilityZonesAll 0).zone }}
---
apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
  labels:
    kops.k8s.io/cluster: {{ $kopsName }}.{{ $dnsZone }}
  name: bastion-workers-zone-{{ $value.name }}
spec:
  additionalUserData:
    - name: protect-kernel-defaults.sh
      type: text/x-shellscript
      content: |
        #!/bin/sh
        cat <<EOF > /etc/sysctl.d/90-kubelet.conf
        vm.overcommit_memory=1
        kernel.panic=10
        kernel.panic_on_oops=1
        EOF
        sysctl -p /etc/sysctl.d/90-kubelet.conf
{{- if $registryProxy }}
    - name: docker-registry-proxy.sh
      type: text/x-shellscript
      content: |
        #!/bin/sh

        # Add environment vars pointing Docker to use the proxy
        # https://docs.docker.com/config/daemon/systemd/#httphttps-proxy

        mkdir -p /etc/systemd/system/docker.service.d
        cat << EOD > /etc/systemd/system/docker.service.d/http-proxy.conf
        [Service]
        Environment="HTTP_PROXY={{ $registryProxy }}"
        Environment="HTTPS_PROXY={{ $registryProxy }}"
        EOD

        # Get the CA certificate from the proxy and make it a trusted root.
        curl {{ $registryProxy }}ca.crt > /usr/share/ca-certificates/docker_registry_proxy.crt
        echo "docker_registry_proxy.crt" >> /etc/ca-certificates.conf
        update-ca-certificates --fresh

        # Reload systemd
        systemctl daemon-reload

        # Restart dockerd
        systemctl restart docker.service
{{- end }}
  cloudLabels:
    {{- range $key, $value := $instanceGroups.bastionWorkersGroup1.cloudLabels }}
      {{ $key }}: "{{ $value }}"
      {{- end }}
  associatePublicIp: true
  image: {{ $instanceGroups.bastionWorkersGroup1.image }}
  machineType: {{ $instanceGroups.bastionWorkersGroup1.machineType }}
  maxSize: {{ $instanceGroups.bastionWorkersGroup1.maxSize }}
  minSize: {{ $instanceGroups.bastionWorkersGroup1.minSize }}
  role: Bastion
  subnets:
    - public-{{ $value.name }}
  {{- end }}
  {{- end }}
  {{- end }}

  #
  #  threatstack-master group
  #
  {{- if .enableThreatstackMasterGroup1 -}}
  {{- range $key, $value := .availabilityZonesThreatstackMaster }}
---
apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
  labels:
    kops.k8s.io/cluster: {{ $kopsName }}.{{ $dnsZone }}
  name: threatstack-master-zone-{{ $value.name }}
spec:
  additionalUserData:
    - name: protect-kernel-defaults.sh
      type: text/x-shellscript
      content: |
        #!/bin/sh
        cat <<EOF > /etc/sysctl.d/90-kubelet.conf
        vm.overcommit_memory=1
        kernel.panic=10
        kernel.panic_on_oops=1
        EOF
        sysctl -p /etc/sysctl.d/90-kubelet.conf
{{- if $registryProxy }}
    - name: docker-registry-proxy.sh
      type: text/x-shellscript
      content: |
        #!/bin/sh

        # Add environment vars pointing Docker to use the proxy
        # https://docs.docker.com/config/daemon/systemd/#httphttps-proxy

        mkdir -p /etc/systemd/system/docker.service.d
        cat << EOD > /etc/systemd/system/docker.service.d/http-proxy.conf
        [Service]
        Environment="HTTP_PROXY={{ $registryProxy }}"
        Environment="HTTPS_PROXY={{ $registryProxy }}"
        EOD

        # Get the CA certificate from the proxy and make it a trusted root.
        curl {{ $registryProxy }}ca.crt > /usr/share/ca-certificates/docker_registry_proxy.crt
        echo "docker_registry_proxy.crt" >> /etc/ca-certificates.conf
        update-ca-certificates --fresh

        # Reload systemd
        systemctl daemon-reload

        # Restart dockerd
        systemctl restart docker.service
{{- end }}
  cloudLabels:
    {{- range $key, $value := $instanceGroups.threatstackMaster.cloudLabels }}
      {{ $key }}: "{{ $value }}"
      {{- end }}
  image: {{ $instanceGroups.threatstackMaster.image }}
  machineType: {{ $instanceGroups.threatstackMaster.machineType }}
  maxSize: {{ $instanceGroups.threatstackMaster.maxSize }}
  minSize: {{ $instanceGroups.threatstackMaster.minSize }}
  nodeLabels:
    kops.k8s.io/instancegroup: threatstack-master-zone-{{ $value.name }}
    {{- range $key, $value := $instanceGroups.threatstackMaster.nodeLabels }}
    {{ $key }}: "{{ $value }}"
    {{- end }}
  {{ if $instanceGroups.threatstackMaster.taints.enable }}
  taints:
    {{- range $key, $value := $instanceGroups.threatstackMaster.taints.items }}
    - "{{ $value }}"
    {{- end }}
  {{- end }}
  role: Node
  subnets:
    - threatstack-master-zone-{{ $value.name }}
  {{- end }}
  {{- end }}

#######################################################
# Worker node group - all zones
#######################################################
{{- $availabilityZonesAll := .availabilityZonesAll }}

{{- range $key, $value := .workerInstanceGroupsAllZones }}
#######################################################
# Worker node group - all zones - {{ $key }}
#######################################################
{{- range $azKey, $azValue := $availabilityZonesAll }}
---
apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
  labels:
    kops.k8s.io/cluster: {{ $kopsName }}.{{ $dnsZone }}
  name: {{ $key }}-zone-{{ $azValue.name }}
spec:
  additionalUserData:
    - name: protect-kernel-defaults.sh
      type: text/x-shellscript
      content: |
        #!/bin/sh
        cat <<EOF > /etc/sysctl.d/90-kubelet.conf
        vm.overcommit_memory=1
        kernel.panic=10
        kernel.panic_on_oops=1
        EOF
        sysctl -p /etc/sysctl.d/90-kubelet.conf

  cloudLabels:
    {{- range $keyCloudLabels, $valueCloudLabels := $value.cloudLabels }}
      {{ $keyCloudLabels }}: "{{ $valueCloudLabels }}"
      {{- end }}
      k8s.io/cluster-autoscaler/enabled: "true"
      k8s.io/cluster-autoscaler/node-template/label/{{ $kopsName }}.{{ $dnsZone }}/role: "scale-zero"
      k8s.io/cluster-autoscaler/{{ $kopsName }}.{{ $dnsZone }}: "owned"
  image: {{ $value.image }}
  machineType: {{ $value.machineType }}
  maxSize: {{ $value.maxSize }}
  minSize: {{ $value.minSize }}
  nodeLabels:
    kops.k8s.io/instancegroup: {{ $key }}-zone-{{ $azValue.name }}-{{ $value.machineType }}
    {{- if $value.nodeLabels }}
    {{- range $nodeLabelsKey, $nodeLabelsValue := $value.nodeLabels }}
    {{ $nodeLabelsKey }}: "{{ $nodeLabelsValue }}"
    {{- end }}
    {{- end }}
    {{ $kopsName }}.{{ $dnsZone }}: "scale-zero"
    kubernetes-ops/isSpot: "false"
    kubernetes-ops/instanceType: {{ $value.machineType }}
  {{- if $value.taints }}
  taints:
    {{- range $taintsKey, $taintsValue := $value.taints }}
    - "{{ $taintsValue }}"
    {{- end }}
  {{- end }}
  role: Node
  subnets:
  - worker-zone-{{ $azValue.name }}
{{- end }}
{{- end }}
